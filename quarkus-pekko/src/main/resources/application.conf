pekko {
  loglevel = "INFO"
  coordinated-shutdown.exit-jvm = on

  actor {
    provider = "cluster"

    serialization-bindings {
      "com.gdfesta.example.write_side.JacksonJsonSerialization" = jackson-json
    }
  }

  persistence {
    journal {
      plugin = "jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }

    snapshot-store {
      plugin = "jdbc-snapshot-store"
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }

  projection {
    jdbc {
      # choose one of: mysql-dialect, postgres-dialect, mssql-dialect, oracle-dialect or h2-dialect (testing)
      dialect = postgres-dialect
      use-dispatcher = "pekko.projection.jdbc.blocking-jdbc-dispatcher"
      blocking-jdbc-dispatcher {
        type = Dispatcher
        executor = "thread-pool-executor"
        thread-pool-executor {
          # Use same number of threads as connections in the JDBC connection pool.
          fixed-pool-size = 5
        }
        throughput = 1
      }

      offset-store {
        # set this to your database schema if applicable, empty by default
        schema = ""
        # the database table name for the offset store
        table = "pekko_projection_offset_store"

        # the database table name for the projection manangement data
        management-table = "pekko_projection_management"

        # Use lowercase table and column names. 
        # This is mostly useful for H2 and Postgres databases. MySQL and SQL Server are case insensitive. 
        # Oracle schema is case sensitive and is defined with uppercase, this property is therefore ignore when using Oracle
        use-lowercase-schema = true
      }

      debug.verbose-offset-store-logging = false
    }
  }

  remote {
    artery {
      canonical {
        # Use <getHostAddress> to auto-detect the host IP
        # In local dev, this will be 127.0.0.1
        # In Kubernetes, this will be the pod IP
        hostname = "<getHostAddress>"

        port = 25520
      }

      # Bind to all interfaces in Kubernetes
      bind.hostname = "0.0.0.0"
    }
  }

  cluster {
    # Use static seed node for local development
    # In Kubernetes, this will be empty and cluster bootstrap will be used
    seed-nodes = []
    seed-nodes = ${?PEKKO_SEED_NODES}

    shutdown-after-unsuccessful-join-seed-nodes = 60s

    downing-provider-class = "org.apache.pekko.cluster.sbr.SplitBrainResolverProvider"

    sharding {
      number-of-shards = 100
    }
  }

  management {
    cluster.bootstrap {
      contact-point-discovery {
        service-name = "quarkus-pekko"

        
        discovery-method = kubernetes-api
        
        required-contact-point-nr = 1
        required-contact-point-nr = ${?REQUIRED_CONTACT_POINT_NR}
      }
    }

    # Expose port for Kubernetes health check probing.
    http {
      port = 7626
      bind-hostname = "0.0.0.0"
    }
  }

  discovery {
    method = kubernetes-api
  }

  coordinated-shutdown {
    exit-jvm = off
  }
}

jdbc-journal {
  slick = ${slick}
}

jdbc-snapshot-store {
  slick = ${slick}
}

jdbc-read-journal {
  slick = ${slick}
}

pekko-projection-jdbc {
  slick = ${slick}
}

slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    # Default values for local dev (Quarkus Dev Services)
    url = "jdbc:postgresql://localhost:5432/quarkus"
    url = ${?QUARKUS_DATASOURCE_JDBC_URL}
    user = "quarkus"
    user = ${?QUARKUS_DATASOURCE_USERNAME}
    password = "quarkus"
    password = ${?QUARKUS_DATASOURCE_PASSWORD}
    driver = "org.postgresql.Driver"
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }

  # Disable Slick debug logging
  logSql = false
  logStatements = false
}

# Logging configuration to reduce verbosity
pekko.slf4j {
  logger-startup-timeout = 30s
}

pekko.loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]